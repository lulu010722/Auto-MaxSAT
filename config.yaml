model:
  api_key: sk-fee47ec881c446a7a5de72af87943127
  base_url: https://api.deepseek.com
  name: deepseek-chat
  temperature: 0.7

train:
  target_functions:
    # - "int USW::pick_var()"
    # - "void USW::hard_increase_weights()"
    # - "void USW::soft_increase_weights_partial()"
    # - "void USW::soft_increase_weights_not_partial()"
    # - "void USW::hard_smooth_weights()"
    # - "void USW::soft_smooth_weights()"
    # - "void USW::update_clause_weights()"
    - "void USW::increase_clause_weight(int c, double delta)"
    # - "void USW::increase_scores_for_clause(int c, double delta)"
    # - "void USW::decrease_scores_for_satisfied_clause(int c, double delta)"
  related_functions:
    # - "int USW::pick_var()"
    - "void USW::hard_increase_weights()"
    - "void USW::soft_increase_weights_partial()"
    - "void USW::soft_increase_weights_not_partial()"
    - "void USW::hard_smooth_weights()"
    - "void USW::soft_smooth_weights()"
    - "void USW::update_clause_weights()"
    - "void USW::increase_clause_weight(int c, double delta)"
    - "void USW::increase_scores_for_clause(int c, double delta)"
    - "void USW::decrease_scores_for_satisfied_clause(int c, double delta)"
  threshold_rate: 1.05

prompt:
  system: |
    You are an expert in MaxSAT solver optimization with deep knowledge of SAT solving techniques. Your task is to analyze and creatively rewrite specific functions to improve the solver's performance while strictly adhering to these constraints:

    1. Code Transformation Rules:
    - Produce only functional code without explanations, comments or formatting marks
    - The rewritten code must be meaningfully different, not just syntactic variations
    - Maintain the same function signature and interface
    - Only use existing global variables from the original code

    2. Optimization Objectives:
    - Focus on improving clause weighting heuristics effectiveness
    - Consider computational efficiency of weight updates
    - Enhance the solver's ability to escape local optima
    - Maintain or improve solution quality

    3. Innovation Guidelines:
    - Consider novel weighting strategies like multiplicative vs additive updates
    - Explore dynamic adaptation of delta scaling
    - Implement smoothing techniques for weight changes
    - Incorporate reinforcement learning concepts where applicable

  user: |
    Please rewrite the following clause weight adjustment function with innovative improvements.

    Function to rewrite:
    %s

    Current implementation context (ended with ---):
    <original code here>

    %s
    ---

  # system: |
  #   You are a MaxSAT-RL hybrid system expert.
  #   Rewrite the function using reinforcement learning concepts
  #   with these SPECIFIC techniques:

  #   1. **Reward Shaping**: Design immediate rewards based on:
  #      - Clause satisfaction state changes
  #      - Local search progress metrics
  #      - Conflict frequency reduction

  #   2. **Update Rules**: Implement either:
  #      - Q-learning style weight updates
  #      - Policy gradient-based adjustments
  #      - Eligibility traces for long-term credit assignment

  #   3. **Constraints**:
  #      - Keep update computational complexity O(1)
  #      - Maintain thread-safety
  #      - Use existing solver state variables only

  #   Produce 3 variants with different reward functions.

  # system: |
  #   You are designing a bandit-based clause weighting system.
  #   Apply these MAB techniques:

  #   1. **Arm Selection**:
  #      - Treat each clause as an arm
  #      - Use UCB1 or Thompson sampling for selection

  #   2. **Reward Definition**:
  #      - Clause participation in deriving conflicts
  #      - LBD reduction contribution
  #      - Propagation activity

  #   3. **Implementation Requirements**:
  #      - Maintain clause weight normalization
  #      - Add no more than 2 lines of statistics tracking
  #      - Keep memory overhead < 8 bytes/clause

  # system: |
  #   You are building a policy network for clause weighting.
  #   Apply these DRL techniques:

  #   1. **State Representation**:
  #      - Use clause activity history (last 10 steps)
  #      - Normalized LBD and size
  #      - Restart cycle phase

  #   2. **Policy Update**:
  #      - REINFORCE algorithm with baseline
  #      - Natural policy gradient variants
  #      - Advantage Actor-Critic style updates

  #   3. **Efficiency Constraints**:
  #      - Maximum 3 additional floating-point operations
  #      - No dynamic memory allocation
  #      - Thread-local storage only


runtime:
  cutoff_time: 60
  epoch: 10
  benchmark_iter_time: 5
